{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Julialunna/Fed-DP-PSO/blob/main/Fed_DP_PSO_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flwr\n",
        "!pip install flwr-datasets\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCiNUXj4TdEZ",
        "outputId": "43243109-d0b6-495f-beb9-7eba3bc47817",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flwr in /usr/local/lib/python3.11/dist-packages (1.19.0)\n",
            "Requirement already satisfied: click<8.2.0 in /usr/local/lib/python3.11/dist-packages (from flwr) (8.1.8)\n",
            "Requirement already satisfied: cryptography<45.0.0,>=44.0.1 in /usr/local/lib/python3.11/dist-packages (from flwr) (44.0.3)\n",
            "Requirement already satisfied: grpcio!=1.65.0,<2.0.0,>=1.62.3 in /usr/local/lib/python3.11/dist-packages (from flwr) (1.73.1)\n",
            "Requirement already satisfied: iterators<0.0.3,>=0.0.2 in /usr/local/lib/python3.11/dist-packages (from flwr) (0.0.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from flwr) (2.0.2)\n",
            "Requirement already satisfied: pathspec<0.13.0,>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from flwr) (0.12.1)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.21.6 in /usr/local/lib/python3.11/dist-packages (from flwr) (4.25.8)\n",
            "Requirement already satisfied: pycryptodome<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from flwr) (3.23.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /usr/local/lib/python3.11/dist-packages (from flwr) (6.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from flwr) (2.32.3)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.5.0 in /usr/local/lib/python3.11/dist-packages (from flwr) (13.9.4)\n",
            "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from flwr) (2.2.1)\n",
            "Requirement already satisfied: tomli-w<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from flwr) (1.2.0)\n",
            "Requirement already satisfied: typer<0.13.0,>=0.12.5 in /usr/local/lib/python3.11/dist-packages (from flwr) (0.12.5)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<45.0.0,>=44.0.1->flwr) (1.17.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr) (2025.7.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.5.0->flwr) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.5.0->flwr) (2.19.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from typer<0.13.0,>=0.12.5->flwr) (4.14.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.13.0,>=0.12.5->flwr) (1.5.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<45.0.0,>=44.0.1->flwr) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.5.0->flwr) (0.1.2)\n",
            "Requirement already satisfied: flwr-datasets in /usr/local/lib/python3.11/dist-packages (0.5.0)\n",
            "Requirement already satisfied: datasets<=3.1.0,>=2.14.6 in /usr/local/lib/python3.11/dist-packages (from flwr-datasets) (3.1.0)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.7.5 in /usr/local/lib/python3.11/dist-packages (from flwr-datasets) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from flwr-datasets) (2.0.2)\n",
            "Requirement already satisfied: seaborn<0.14.0,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from flwr-datasets) (0.13.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from flwr-datasets) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr-datasets) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr-datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr-datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr-datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr-datasets) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr-datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr-datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets<=3.1.0,>=2.14.6->flwr-datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr-datasets) (3.12.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr-datasets) (0.33.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr-datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr-datasets) (6.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.5->flwr-datasets) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.5->flwr-datasets) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.5->flwr-datasets) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.5->flwr-datasets) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.5->flwr-datasets) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.5->flwr-datasets) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.5->flwr-datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr-datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr-datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr-datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr-datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr-datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr-datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr-datasets) (1.20.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets<=3.1.0,>=2.14.6->flwr-datasets) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets<=3.1.0,>=2.14.6->flwr-datasets) (1.1.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<=3.1.0,>=2.14.6->flwr-datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<=3.1.0,>=2.14.6->flwr-datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.7.5->flwr-datasets) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<=3.1.0,>=2.14.6->flwr-datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<=3.1.0,>=2.14.6->flwr-datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<=3.1.0,>=2.14.6->flwr-datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<=3.1.0,>=2.14.6->flwr-datasets) (2025.7.14)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.12.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.7.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opacus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQjuVbO7Z32d",
        "outputId": "f5893e7c-edc6-4d93-86b0-6194d0ac6a42"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opacus\n",
            "  Downloading opacus-1.5.4-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.11/dist-packages (from opacus) (2.0.2)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from opacus) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.11/dist-packages (from opacus) (1.16.0)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from opacus) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (2024.9.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->opacus) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->opacus) (3.0.2)\n",
            "Downloading opacus-1.5.4-py3-none-any.whl (254 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.4/254.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, opacus\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 opacus-1.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split, Subset, TensorDataset\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "import copy\n",
        "import random\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "\n",
        "from flwr_datasets.partitioner import DirichletPartitioner, IidPartitioner\n",
        "from flwr_datasets import FederatedDataset\n",
        "\n",
        "from opacus import PrivacyEngine\n",
        "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
        "from opacus.accountants.utils import get_noise_multiplier\n",
        "from opacus.accountants import RDPAccountant"
      ],
      "metadata": {
        "id": "L8fXkrgtVXRJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self, device, input_size=28*28, hidden_size=256, num_classes=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.device = device\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
        "        self.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Achatar o tensor de entrada\n",
        "        y = self.fc1(x)\n",
        "        y = self.relu(y)\n",
        "        y = self.fc2(y)\n",
        "        y = self.relu(y)\n",
        "        y = self.fc3(y)\n",
        "\n",
        "        return y"
      ],
      "metadata": {
        "id": "xPUzg43AYvS-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definições dos hiperparâmetros\n",
        "NUM_CLIENTES = 10\n",
        "NUM_PARTICULAS = 5\n",
        "NUM_RODADAS = 10\n",
        "NUM_DIGITOS = 10\n",
        "# INERCIA, C1, C2 = 0.8, 1.5,  1.9\n",
        "INERCIA, C1, C2 = 0.7, 1.4, 1.4\n",
        "# INERCIA, C1, C2 = 0.9, 1.5, 1.5\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BATCH_SIZE = 240\n",
        "\n",
        "print(f'training on {DEVICE}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thy82r1LYv9F",
        "outputId": "7f736478-b91e-45e7-e153-5cb2083b138a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ALPHA = 1\n",
        "# numero = 42\n",
        "# numero = 88\n",
        "numero = 90\n",
        "# numero = 36\n",
        "print(numero)\n",
        "random.seed(numero)\n",
        "torch.manual_seed(numero)\n",
        "torch.cuda.manual_seed(numero)\n",
        "\n",
        "# Criando o modelo global\n",
        "modelo_global = MLP(DEVICE)\n",
        "criterio = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "# criterio = nn.CrossEntropyLoss()\n",
        "\n",
        "class Particula:\n",
        "    def __init__(self, particle_id, modelo_cliente, teste):\n",
        "        self.particle_id = particle_id\n",
        "        # self.pesos = copy.deepcopy(modelo_cliente.state_dict())\n",
        "        self.pesos = {f\"_module.{key}\": value.clone() for key, value in modelo_cliente.state_dict().items()}\n",
        "        self.device = modelo_cliente.device\n",
        "        self.teste = teste\n",
        "\n",
        "        # Adiciona ruído leve nos pesos para quebrar simetria inicial\n",
        "        for name in self.pesos:\n",
        "            self.pesos[name] += 0.01 * torch.randn_like(self.pesos[name])\n",
        "\n",
        "        self.melhor_pesos = copy.deepcopy(self.pesos)\n",
        "        self.melhor_erro = float('inf')\n",
        "        self.velocidade = {name: torch.zeros_like(param) for name, param in self.pesos.items()}\n",
        "\n",
        "\n",
        "    def atualizar_pso(self, global_best_pesos, INERCIA, C1, C2):\n",
        "        MAX_VELOCITY = 0.1  # Limite para evitar oscilações grandes\n",
        "        if(round == 0):\n",
        "          global_best_weights_adjusteds = {f\"_module.{key}\": value for key, value in global_best_pesos.items()}\n",
        "        for name in self.pesos:\n",
        "            local_rand = random.random()\n",
        "            global_rand = random.random()\n",
        "            self.velocidade[name] = (\n",
        "                INERCIA * self.velocidade[name]\n",
        "                + C1 * local_rand * (self.melhor_pesos[name] - self.pesos[name])\n",
        "                + C2 * global_rand * (global_best_pesos[name] - self.pesos[name])\n",
        "            )\n",
        "\n",
        "            # Clipping da velocidade\n",
        "            self.velocidade[name] = torch.clamp(self.velocidade[name], -MAX_VELOCITY, MAX_VELOCITY)\n",
        "\n",
        "            # Atualiza os pesos com a nova velocidade\n",
        "            self.pesos[name] += self.velocidade[name]\n",
        "\n",
        "    def avaliar_perda(self, modelo_cliente, criterio):\n",
        "        modelo_cliente.load_state_dict(self.pesos)\n",
        "        modelo_cliente.eval()\n",
        "        total_loss = 0\n",
        "        device = next(modelo_cliente.parameters()).device\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in self.teste:\n",
        "                inputs, labels =  inputs.to(DEVICE), labels.to(DEVICE)\n",
        "                outputs = modelo_cliente(inputs)\n",
        "                loss = criterio(outputs, labels)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "\n",
        "        return total_loss / len(self.teste)\n",
        "\n",
        "class Cliente:\n",
        "    def __init__(self, cliente_id, modelo_global, dados, test, num_particulas):\n",
        "        self.cliente_id = cliente_id\n",
        "        self.modelo = copy.deepcopy(modelo_global)  # Cada cliente tem seu próprio modelo\n",
        "        self.dados = dados\n",
        "        self.test = test\n",
        "        self.num_particulas = num_particulas\n",
        "        self.particulas = []\n",
        "        self.melhor_particula = None\n",
        "        self.inicializar_particulas(num_particulas, test)\n",
        "        self.optimizer = optim.Adam(self.modelo.parameters(), lr=0.0055)\n",
        "\n",
        "    def inicializar_particulas(self, num_particulas, test):\n",
        "        \"\"\"Cria um conjunto de partículas associadas ao cliente.\"\"\"\n",
        "        self.particulas = [Particula(i, self.modelo, test) for i in range(num_particulas)]\n",
        "\n",
        "    def treinar_com_pso(self, INERCIA, C1, C2, global_best_pesos, criterio):\n",
        "        \"\"\"Treina as partículas usando PSO e atualiza a melhor partícula local.\"\"\"\n",
        "\n",
        "        for particula in self.particulas:\n",
        "            particula.atualizar_pso(global_best_pesos, INERCIA, C1, C2)\n",
        "            erro = particula.avaliar_perda(self.modelo, criterio)\n",
        "            if erro < particula.melhor_erro:\n",
        "                particula.melhor_erro = erro\n",
        "                particula.melhor_pesos = copy.deepcopy(particula.pesos)\n",
        "\n",
        "        self.selecionar_melhor_particula()\n",
        "        # modelo_global.load_state_dict(self.melhor_particula.pesos)\n",
        "\n",
        "    def refinar_com_adam(self, criterio):\n",
        "        \"\"\"Refina os pesos da melhor partícula usando Adam.\"\"\"\n",
        "        self.modelo.load_state_dict(self.melhor_particula.melhor_pesos)\n",
        "        # self.modelo.load_state_dict(modelo_global.state_dict())\n",
        "        device = next(self.modelo.parameters()).device\n",
        "\n",
        "        self.modelo.train()\n",
        "        for i in range(1):\n",
        "          with BatchMemoryManager(data_loader=self.dados, max_physical_batch_size=BATCH_SIZE, optimizer=self.optimizer) as new_data_loader:\n",
        "            for batch in self.dados:\n",
        "                inputs, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.modelo(inputs)\n",
        "                loss = criterio(outputs, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "        self.melhor_particula.melhor_pesos = copy.deepcopy(self.modelo.state_dict())\n",
        "        self.melhor_particula.melhor_erro = self.calcular_loss(self.modelo, criterio, self.test)\n",
        "\n",
        "    def calcular_loss(self, modelo, criterio, dados):\n",
        "        self.modelo.eval()\n",
        "        total_loss = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in dados:\n",
        "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "                outputs = modelo(inputs)\n",
        "                loss = criterio(outputs, labels)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "        return total_loss / len(dados)\n",
        "\n",
        "    def selecionar_melhor_particula(self):\n",
        "        \"\"\"Seleciona a melhor partícula do cliente.\"\"\"\n",
        "        self.melhor_particula = min(self.particulas, key=lambda p: p.melhor_erro)\n",
        "\n",
        "\n",
        "def treinar_federado(modelo_global, clientes, criterio, num_rodadas, INERCIA, C1, C2, testloader, validationloader):\n",
        "    \"\"\"Treina os clientes localmente e sincroniza com o servidor central, validando a acurácia.\"\"\"\n",
        "\n",
        "    melhor_peso_global = {f\"_module.{key}\": value.clone() for key, value in modelo_global.state_dict().items()}\n",
        "    # melhor_peso_global =  copy.deepcopy(modelo_global.state_dict())\n",
        "    melhor_erro_global = float('inf')\n",
        "    soma = 0.0;\n",
        "    for rodada in range(num_rodadas):\n",
        "        resultados_rodada = []\n",
        "\n",
        "        for cliente in clientes:\n",
        "          cliente.modelo._module.load_state_dict(modelo_global.state_dict())\n",
        "          cliente.treinar_com_pso(INERCIA, C1, C2, melhor_peso_global, criterio)  # Treino com PSO\n",
        "          cliente.refinar_com_adam(criterio)  # Refinamento com Adam\n",
        "          erro_cliente = cliente.melhor_particula.melhor_erro  # Obtém o melhor erro do cliente\n",
        "          pesos_cliente = cliente.melhor_particula.melhor_erro  # Obtém os pesos do modelo do cliente\n",
        "          resultados_rodada.append((cliente.cliente_id, erro_cliente))\n",
        "\n",
        "        resultados_sorted = sorted(resultados_rodada, key=lambda x: x[1])\n",
        "\n",
        "        top_3_results = resultados_sorted[:1]\n",
        "\n",
        "\n",
        "        for i in range(len(resultados_sorted)):\n",
        "          print(resultados_sorted[i])\n",
        "\n",
        "        melhor_cliente = random.choice(top_3_results)\n",
        "        melhor_cliente_id = melhor_cliente[0]\n",
        "        melhor_erro_cliente = melhor_cliente[1]\n",
        "\n",
        "        melhor_peso_global = copy.deepcopy(clientes[melhor_cliente_id].melhor_particula.melhor_pesos)\n",
        "        melhor_peso_global_adjusted =  {key.replace(\"_module.\", \"\"): value for key, value in melhor_peso_global.items()}\n",
        "        melhor_erro_global = melhor_erro_cliente\n",
        "\n",
        "        modelo_global.load_state_dict(melhor_peso_global_adjusted)\n",
        "        # modelo_global.load_state_dict(melhor_peso_global)\n",
        "\n",
        "        test_loss, test_accuracy = avaliar_modelo(modelo_global, criterio, validationloader)\n",
        "        soma += test_accuracy\n",
        "        test_accuracy= test_accuracy*100\n",
        "        print(f\"epsilon: {privacy_engines[0].get_epsilon(delta=1e-5)}\")\n",
        "        print(f\"Rodada {rodada+1}/{num_rodadas}: Cliente {melhor_cliente_id} enviou os pesos!\")\n",
        "        print(f\"Erro Global Atualizado: {melhor_erro_global:.4f}\")\n",
        "        print(\"Epsilon 10 desbalanceado extremo \")\n",
        "        print(f\"Teste -> Perda: {test_loss: .4f}, Acurácia: {test_accuracy: .4f}%\\n\")\n",
        "\n",
        "    print(f\"Acurácia média: {soma/num_rodadas: .2f}\")\n",
        "    print(\"Treinamento Federado Finalizado!\")\n",
        "\n",
        "def avaliar_modelo(modelo, criterio, testloader):\n",
        "    \"\"\"Avalia o modelo global no conjunto de teste.\"\"\"\n",
        "    modelo.eval()  # Modo de avaliação\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = modelo(inputs)\n",
        "            loss = criterio(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "    test_loss = total_loss / len(testloader)\n",
        "    test_accuracy = (correct / total_samples)\n",
        "\n",
        "    return test_loss, test_accuracy\n",
        "#criando dataloader de teste\n",
        "from torchvision.datasets import MNIST\n",
        "mnist_test = MNIST(root=\"./data\", train=False, download=True)\n",
        "\n",
        "#normalizacao\n",
        "X_test = mnist_test.data.numpy().astype(\"float32\") / 255.0\n",
        "y_test = mnist_test.targets.numpy()\n",
        "\n",
        "X_test = torch.tensor(X_test).unsqueeze(1)\n",
        "X_test = (X_test - 0.1307) / 0.3081\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "from torch.utils.data import TensorDataset\n",
        "test_dataset_full = TensorDataset(X_test, y_test)\n",
        "\n",
        "num_total = len(test_dataset_full)\n",
        "num_val   = int(0.4 * num_total)\n",
        "num_test  = num_total - num_val\n",
        "\n",
        "val_dataset, test_dataset = random_split(test_dataset_full, [num_val, num_test], generator=torch.Generator().manual_seed(numero))\n",
        "\n",
        "# Loaders separados\n",
        "validationloader = DataLoader(val_dataset, batch_size=240, shuffle=False, num_workers=2, pin_memory=True)\n",
        "testloader = DataLoader(test_dataset, batch_size=240, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "#criando dataloaders de treino\n",
        "from datasets import Dataset as HFDataset\n",
        "from flwr_datasets.partitioner import DirichletPartitioner\n",
        "from flwr_datasets.visualization import plot_label_distributions\n",
        "\n",
        "mnist_raw = MNIST(root=\"./data\", train=True, download=True)\n",
        "\n",
        "imgs, labels = [], []\n",
        "for img, lbl in mnist_raw:\n",
        "    t = transforms.functional.to_tensor(img)          # (1,28,28) float32 em [0,1]\n",
        "    t = (t - 0.1307) / 0.3081                         # normalização MNIST\n",
        "    imgs.append(t.view(-1))                           # opcional: achata p/ 784\n",
        "    labels.append(lbl)\n",
        "\n",
        "# 3) Cria HuggingFace-Dataset já em formato Torch (evita .with_transform depois)\n",
        "hf_dataset = HFDataset.from_dict(\n",
        "    {\"image\": imgs, \"label\": labels}\n",
        ").with_format(\"torch\")\n",
        "\n",
        "\n",
        "#Para testa balanceado comenta esse\n",
        "partitioner = DirichletPartitioner( num_partitions=NUM_CLIENTES, partition_by=\"label\", alpha=ALPHA, seed=numero\n",
        ")\n",
        "#e descomenta esse\n",
        "# partitioner = IidPartitioner(\n",
        "#     num_partitions=NUM_CLIENTES\n",
        "# )\n",
        "\n",
        "partitioner.dataset = hf_dataset\n",
        "\n",
        "def get_trainloader(client_id: int):\n",
        "    ds = partitioner.load_partition(client_id)        # já em torch.Tensor\n",
        "    return DataLoader(ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "# (Opcional) Visualização da distribuição\n",
        "fig, ax, df = plot_label_distributions(\n",
        "    partitioner,\n",
        "    label_name=\"label\",\n",
        "    plot_type=\"bar\",\n",
        "    size_unit=\"absolute\",\n",
        "    partition_id_axis=\"x\",\n",
        "    legend=True,\n",
        "    verbose_labels=True,\n",
        "    max_num_partitions=30,\n",
        "    title=\"Per Partition Labels Distribution\",\n",
        ")\n",
        "\n",
        "clientes = [Cliente(i, modelo_global, get_trainloader(i), validationloader, NUM_PARTICULAS) for i in range(NUM_CLIENTES)]\n",
        "privacy_engines = [PrivacyEngine() for _ in range(NUM_CLIENTES)]\n",
        "for i in range(NUM_CLIENTES):\n",
        "    clientes[i].modelo.train()\n",
        "    clientes[i].modelo, clientes[i].optimizer, clientes[i].dados = privacy_engines[i].make_private_with_epsilon(\n",
        "        module=clientes[i].modelo,\n",
        "        optimizer=clientes[i].optimizer,\n",
        "        data_loader=clientes[i].dados,\n",
        "        epochs=NUM_RODADAS ,\n",
        "        target_epsilon=5,\n",
        "        target_delta=1e-5,\n",
        "        max_grad_norm=1.0\n",
        "    )\n",
        "\n",
        "\n",
        "print(modelo_global.state_dict()['fc1.weight'][0,0])\n",
        "treinar_federado(modelo_global, clientes, criterio, NUM_RODADAS, INERCIA, C1, C2, testloader, validationloader)\n",
        "print(modelo_global.state_dict()['fc1.weight'][0,0])\n",
        "\n",
        "soma=0\n",
        "test_loss, test_accuracy = avaliar_modelo(modelo_global, criterio, testloader)\n",
        "soma += test_accuracy\n",
        "\n",
        "# if (rodada+1) % 10 == 0:\n",
        "test_accuracy= test_accuracy*100\n",
        "print(f\"Teste final -> Perda: {test_loss: .4f}, Acurácia: {test_accuracy: .4f}%\\n\")\n",
        "\n",
        "\n",
        "for i in range(NUM_CLIENTES):\n",
        "    print(privacy_engines[i].get_epsilon(delta=1e-5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Mg24yCpmYzrj",
        "outputId": "b8b72819-137e-4a9f-a925-caf3ee77cf3f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/flwr_datasets/metrics/utils.py:130: UserWarning: The verbose names can not be established. The column specified by 'column_name' needs to be of type 'ClassLabel' to create a verbose names. The available names will used.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-0.0227, device='cuda:0')\n",
            "(4, 1.3208785758298986)\n",
            "(0, 1.4221626379910637)\n",
            "(7, 1.4319406467325546)\n",
            "(8, 1.4695374544929056)\n",
            "(5, 1.6307335390764124)\n",
            "(6, 1.6400928006452673)\n",
            "(1, 1.6853959770763622)\n",
            "(9, 1.8671552924548878)\n",
            "(3, 1.8827748929753023)\n",
            "(2, 2.2573414409861847)\n",
            "epsilon: 2.15018528451164\n",
            "Rodada 1/10: Cliente 4 enviou os pesos!\n",
            "Erro Global Atualizado: 1.3209\n",
            "Epsilon 10 desbalanceado extremo \n",
            "Teste -> Perda:  1.3209, Acurácia:  69.6000%\n",
            "\n",
            "(0, 1.0481580706203686)\n",
            "(7, 1.1356631377164055)\n",
            "(8, 1.1473220727022957)\n",
            "(9, 1.212075380718007)\n",
            "(5, 1.2312906489652746)\n",
            "(4, 1.2513428645975448)\n",
            "(1, 1.2795857752070707)\n",
            "(3, 1.4161753724603092)\n",
            "(6, 1.4171091388253605)\n",
            "(2, 1.5140615631552303)\n",
            "epsilon: 2.643434843937355\n",
            "Rodada 2/10: Cliente 0 enviou os pesos!\n",
            "Erro Global Atualizado: 1.0482\n",
            "Epsilon 10 desbalanceado extremo \n",
            "Teste -> Perda:  1.0482, Acurácia:  78.6000%\n",
            "\n",
            "(0, 0.9616968491498161)\n",
            "(7, 1.026045981575461)\n",
            "(8, 1.0828401972265804)\n",
            "(4, 1.1233472403358011)\n",
            "(9, 1.2101006437750423)\n",
            "(3, 1.2312650329926436)\n",
            "(5, 1.274179507704342)\n",
            "(1, 1.3146400311413933)\n",
            "(2, 1.5018943267710068)\n",
            "(6, 1.5310489850885727)\n",
            "epsilon: 3.0401013400444117\n",
            "Rodada 3/10: Cliente 0 enviou os pesos!\n",
            "Erro Global Atualizado: 0.9617\n",
            "Epsilon 10 desbalanceado extremo \n",
            "Teste -> Perda:  0.9617, Acurácia:  81.9250%\n",
            "\n",
            "(7, 0.949102875064401)\n",
            "(8, 0.9529021382331848)\n",
            "(0, 0.9636466748574201)\n",
            "(5, 0.983655687640695)\n",
            "(9, 1.012626455110662)\n",
            "(6, 1.0894352057400871)\n",
            "(4, 1.1123981966691858)\n",
            "(3, 1.1797274701735552)\n",
            "(1, 1.1857628261341768)\n",
            "(2, 1.517964573467479)\n",
            "epsilon: 3.3862725899466364\n",
            "Rodada 4/10: Cliente 7 enviou os pesos!\n",
            "Erro Global Atualizado: 0.9491\n",
            "Epsilon 10 desbalanceado extremo \n",
            "Teste -> Perda:  0.9491, Acurácia:  81.4750%\n",
            "\n",
            "(7, 0.9255090390934664)\n",
            "(9, 0.9321840615833507)\n",
            "(0, 0.9334725597325493)\n",
            "(8, 0.9339543791378245)\n",
            "(5, 1.0198279303662918)\n",
            "(6, 1.02853546072455)\n",
            "(4, 1.1437760100645178)\n",
            "(1, 1.1579427859362434)\n",
            "(2, 1.1610940414316513)\n",
            "(3, 1.1679229455835678)\n",
            "epsilon: 3.6995041038629184\n",
            "Rodada 5/10: Cliente 7 enviou os pesos!\n",
            "Erro Global Atualizado: 0.9255\n",
            "Epsilon 10 desbalanceado extremo \n",
            "Teste -> Perda:  0.9255, Acurácia:  83.7750%\n",
            "\n",
            "(5, 0.925351363771102)\n",
            "(0, 0.9411109370343825)\n",
            "(8, 0.9545736382989323)\n",
            "(7, 0.9745821111342486)\n",
            "(9, 0.9763005445985233)\n",
            "(6, 1.0310851019971512)\n",
            "(1, 1.0315310919986052)\n",
            "(3, 1.0415278217371773)\n",
            "(4, 1.135263961904189)\n",
            "(2, 1.1989928203470566)\n",
            "epsilon: 3.9889068649955264\n",
            "Rodada 6/10: Cliente 5 enviou os pesos!\n",
            "Erro Global Atualizado: 0.9254\n",
            "Epsilon 10 desbalanceado extremo \n",
            "Teste -> Perda:  0.9254, Acurácia:  84.0500%\n",
            "\n",
            "(8, 0.8910315562697018)\n",
            "(0, 0.9056914694168988)\n",
            "(5, 0.9071894042632159)\n",
            "(9, 0.929005643900703)\n",
            "(7, 0.9372591271119959)\n",
            "(3, 1.0168512744062088)\n",
            "(6, 1.0966404956929825)\n",
            "(2, 1.0988041933845072)\n",
            "(1, 1.1175233406179093)\n",
            "(4, 1.1879182002123665)\n",
            "epsilon: 4.259978253720932\n",
            "Rodada 7/10: Cliente 8 enviou os pesos!\n",
            "Erro Global Atualizado: 0.8910\n",
            "Epsilon 10 desbalanceado extremo \n",
            "Teste -> Perda:  0.8910, Acurácia:  85.8000%\n",
            "\n",
            "(8, 0.858994887155645)\n",
            "(0, 0.8804945840555078)\n",
            "(5, 0.9297808548983406)\n",
            "(7, 0.9462604733074412)\n",
            "(9, 0.9598146256278542)\n",
            "(3, 1.0025093765819775)\n",
            "(1, 1.0277938036357654)\n",
            "(6, 1.057131942580728)\n",
            "(4, 1.0880710517658907)\n",
            "(2, 1.1269597025478588)\n",
            "epsilon: 4.516353805384476\n",
            "Rodada 8/10: Cliente 8 enviou os pesos!\n",
            "Erro Global Atualizado: 0.8590\n",
            "Epsilon 10 desbalanceado extremo \n",
            "Teste -> Perda:  0.8590, Acurácia:  87.3000%\n",
            "\n",
            "(8, 0.8581848214654362)\n",
            "(0, 0.9114751079503227)\n",
            "(5, 0.9138494063826168)\n",
            "(7, 0.9595552717938143)\n",
            "(9, 0.9874376900055829)\n",
            "(6, 1.0323708653450012)\n",
            "(1, 1.0392151124337141)\n",
            "(3, 1.0588444716790144)\n",
            "(4, 1.1013277278226965)\n",
            "(2, 1.1363270983976477)\n",
            "epsilon: 4.760592724741163\n",
            "Rodada 9/10: Cliente 8 enviou os pesos!\n",
            "Erro Global Atualizado: 0.8582\n",
            "Epsilon 10 desbalanceado extremo \n",
            "Teste -> Perda:  0.8582, Acurácia:  87.2500%\n",
            "\n",
            "(0, 0.8646087716607487)\n",
            "(8, 0.8885799926870009)\n",
            "(7, 0.8968748765833238)\n",
            "(5, 0.9502016095554128)\n",
            "(9, 0.9830772280693054)\n",
            "(4, 0.9960685758029714)\n",
            "(6, 1.0406372582211214)\n",
            "(1, 1.0446388195542728)\n",
            "(3, 1.0884334760553696)\n",
            "(2, 1.132873205577626)\n",
            "epsilon: 4.9945802969477455\n",
            "Rodada 10/10: Cliente 0 enviou os pesos!\n",
            "Erro Global Atualizado: 0.8646\n",
            "Epsilon 10 desbalanceado extremo \n",
            "Teste -> Perda:  0.8646, Acurácia:  86.4750%\n",
            "\n",
            "Acurácia média:  0.83\n",
            "Treinamento Federado Finalizado!\n",
            "tensor(-0.0510, device='cuda:0')\n",
            "Teste final -> Perda:  0.8641, Acurácia:  86.7000%\n",
            "\n",
            "4.9945802969477455\n",
            "4.999714217654657\n",
            "4.994858434388186\n",
            "4.9904385380131755\n",
            "4.998728209277126\n",
            "4.997537714905889\n",
            "4.997161832791698\n",
            "4.993501544461281\n",
            "4.997537714905889\n",
            "4.9923476476438955\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}